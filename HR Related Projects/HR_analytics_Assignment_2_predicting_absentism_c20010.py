# -*- coding: utf-8 -*-
"""Predicting_Absentism_C20010.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BG7JqNW9TcZ4tTRtA6l-jHLu-GHvZpb7
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files
files.upload()

df=pd.read_excel("Absenteeism_at_work.xls")

df.head()

df.columns

df['Absenteeism time in hours'].nunique()

df['Education'].unique()

df.describe()

df.info()

df.isnull().sum()

df['Reason for absence'].nunique()

df1=df.copy()

df1.dropna(axis=0,inplace=True)

df1.head()

reason_columns = pd.get_dummies(df1["Reason for absence"],drop_first=True)
reason_columns.head()

reason_1 = reason_columns.loc[:,:14].max(axis=1)
reason_2 = reason_columns.loc[:,15:17].max(axis=1)
reason_3 = reason_columns.loc[:,18:21].max(axis=1)
reason_4 = reason_columns.loc[:,22:].max(axis=1)

print(reason_4)

df2 = pd.concat([df1.drop("Reason for absence",axis=1), reason_1, reason_2, reason_3, reason_4],axis=1)
df2.head()

df2.info()

df2.drop(['ID'],axis=1,inplace=True)

df2.head()

df2.isnull().sum()

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="median")

imputer=imputer.fit(df2)

imputer = imputer.transform(df2)

data = pd.DataFrame(imputer)
data.head()

data.isnull().sum()

data.columns=['Month of absence','Day of the week' ,'Seasons', 'Transportation Expense', 'Distance to Work','Service time', 'Age',
       'Daily Work Load Average','Hit target', 'Disciplinary failure', 'Education',
       'Children', 'Social drinker','Social smoker','Pet','Weight','Height' ,'Body mass index','Absenteeism Time in Hours', 'Reason_1', 'Reason_2', 'Reason_3', 'Reason_4']

data.head()

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error
from sklearn.preprocessing import StandardScaler

sc=StandardScaler()

data=sc.fit_transform(data)

data=pd.DataFrame(data)

data.head()

data.columns=['Month of absence','Day of the week' ,'Seasons', 'Transportation Expense', 'Distance to Work','Service time', 'Age',
       'Daily Work Load Average','Hit target', 'Disciplinary failure', 'Education',
       'Children', 'Social drinker','Social smoker','Pet','Weight','Height' ,'Body mass index','Absenteeism Time in Hours', 'Reason_1', 'Reason_2', 'Reason_3', 'Reason_4']

data.head()

X=data.drop(["Absenteeism Time in Hours"],axis=1)
Y=data["Absenteeism Time in Hours"]

x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3,random_state=42)

LR= LinearRegression()
LR.fit(x_train,y_train)

y_pred=LR.predict(x_test)

print(mean_squared_error(y_pred,y_test))

print(r2_score(y_pred,y_test))

feature_imp=pd.Series(LR.coef_,index=x_train.columns).sort_values(ascending=False)
print(feature_imp)

fig=plt.figure(figsize=(25,15))
sns.barplot(x=feature_imp, y=feature_imp.index)
plt.xlabel('Feature Importance Score')
plt.ylabel('Features')
plt.title("Important Features")
plt.show()

"""## We need to improve the model significantly . In order to improve the model We need to remove some features like BMI . Distance to Work, Day of the Week .
## The most important features are Reason_3,Reason_1,Reason_4 and Trnsportation expense 
"""



